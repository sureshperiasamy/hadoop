Session 1: How to Solve the Big Data Problem

Assignment 1
 
1.    Various Sources of Big Data:

 

Top 10 Big Data source types are

 

·        Social network profiles

·        Social influence

·        Activity-generated data

·        Software as a Service (SaaS) and cloud applications

·         Public

·        Hadoop MapReduce application results

·        Data warehouse appliances

·        Columnar/NoSQL data sources

·        Network and in-stream monitoring technologies

·        Legacy Documents

 

 

 
2.     3 v’s of Big Data:
 
The 3 V’s of Big Data are
 
·        Volume – Data Size
·        Variety – Data Sources
·        Velocity – Speed of Change
 
 
 
 
 
 
3.    Horizontal Scaling and Vertical Scaling:
 
Horizontal Scaling
Vertical Scaling
·        Adding more machines to the resources is known as Horizontal Scaling.
 
·        Advantage: All of the data is in smaller chunks so program can process them very fast with parallel job distribution among all instance.
 

·        Drawback: The problem is about managing those instances and the complex distributed architecture.
·        Adding more power to the resources is known as Vertical Scaling.
 
·        Advantage: All the data is in a single machine. No need to manage multiple instance.
 

·        Drawback:  The Cost is high in this method.
 

 

 
 
 
4.    Need and Working of Hadoop:
 
The following are the needs and working of Hadoop,
 
·        Need of Hadoop: The complexity of modern analytics needs is outstripping the available computing power of legacy systems. With its distributed processing, Hadoop can handle large volumes of structured and unstructured data more efficiently than the traditional enterprise data warehouse. Because Hadoop is an open source and can run on commodity hardware, the initial cost savings are dramatic and continue to grow with the growth of the organization. Hadoop has a robust Apache community behind it that continues to contribute to its advancement.
·        Working of Hadoop: With the Hadoop Distributed File System the data is written once on the server and subsequently read and re-used many times thereafter. When contrasted with the repeated read/write actions of most other file systems it explains part of the speed with which the speed with which Hadoop operates    
